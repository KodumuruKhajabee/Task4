{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install sentence-transformers langchain chromadb pypdf faiss-cpu  langchain_community scikit-learn matplotlib seaborn numpy mistralai langchain-mistralai langchain_classic"
      ],
      "metadata": {
        "id": "IP07OrZho6il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS,Chroma\n",
        "from langchain_classic.schema import Document\n",
        "import os\n",
        "\n",
        "\n",
        "loader = PyPDFLoader(\"/content/K.Khajabee Resume.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\"Loaded {len(docs)} docs, split into {len(chunks)} chunks\")\n",
        "# inspect one\n",
        "print(chunks[0].page_content[:400])"
      ],
      "metadata": {
        "id": "8gOQU534pDlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating embeddings... this may take a moment.\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "nPr04gAypZN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "jWOclQjOpdZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "Z3_1u0FLpmkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MISTRAL_API_KEY\"] = \"yU8x8V6GtDv2XfYiY6KlDl1yj03IVXrG\""
      ],
      "metadata": {
        "id": "xBgteShFwF8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(model=\"mistral-tiny\")"
      ],
      "metadata": {
        "id": "ULjP4cK3pqBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_classic.chains import create_retrieval_chain\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the following question based only on the provided context:\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "Question: {input}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "_KwPHiLdprRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "wgsAsgsep0S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = create_retrieval_chain(retriever, document_chain)"
      ],
      "metadata": {
        "id": "iKJc_CHoqDPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(model=\"mistral-tiny\")"
      ],
      "metadata": {
        "id": "B4Ru3LoEsBqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"What is netflix system recommendation project ?\"\n",
        "response = rag_chain.invoke({\"input\": user_query})\n",
        "\n",
        "print(\"\\n--- RESPONSE ---\")\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "id": "ClaIguRXsMgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MISTRAL_API_KEY\"] = \"yU8x8V6GtDv2XfYiY6KlDl1yj03IVXrG\""
      ],
      "metadata": {
        "id": "Y3z8nGLossOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujp93CdtysOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}